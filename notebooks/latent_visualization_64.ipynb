{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ctq566/miniconda3/envs/mdm/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Latent Space Visualization\n",
    "It is intended to do something similar to [Visualization and understanding of latent space #12](https://github.com/ChenFengYe/motion-latent-diffusion/issues/12), but for MDM.\n",
    "\n",
    "We take `./assets/direction_number_text_prompts_64.txt` as input, where we have 64 prompts and the repetition is 10.\n",
    "\n",
    "Since `ClassifierFreeSampleModel` is used, we have both conditioned and unconditioned samples. The `diffusion_steps` is 1000, so we would have 2000 samples for each prompt each repetition. Since the number of samples is too large, we only take the latent vector of step 0, 250, 500, 750, and 999.\n",
    "\n",
    "Each `.npy` file contains 64 latent vectors (since we have 64 prompts). They all have names like this `latent_vec_<diffusion_step>_<index>`. If the `index` is even, it means the latent vector is conditioned, otherwise it is unconditioned.\n",
    "\n",
    "For example, `latent_vec_0_0.npy` is the latent vector of the first prompt at step 0, and it is conditioned.\n",
    "\n",
    "We are going to make this notebook more general, so that we can use it for other inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "\n",
    "def load_data(timesteps, repetitions, latent_vec_path='../latent_vec/latent_vec_64/'):\n",
    "    data_conditioned = []\n",
    "    data_unconditioned = []\n",
    "    for i in range(repetitions):\n",
    "        data_conditioned.append(np.load(os.path.join(latent_vec_path, f'latent_vec_{timesteps}_{2 * i}.npy')))\n",
    "        data_unconditioned.append(np.load(os.path.join(latent_vec_path, f'latent_vec_{timesteps}_{2 * i + 1}.npy')))\n",
    "    return np.array(data_conditioned), np.array(data_unconditioned)\n",
    "\n",
    "\n",
    "def preprocess_data(data, repeitions, classes):\n",
    "    data = data.transpose((0, 2, 1, 3)).reshape((repeitions * classes, -1, 512))\n",
    "    data = data.reshape((repeitions * classes, -1))\n",
    "    return data\n",
    "\n",
    "\n",
    "def draw_tsne(data, labels, colors, markers, title='', output_dir='../assets/pdf/latent_vec_64', fig=None, ax=None):\n",
    "    np.random.seed(42)\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    if fig is None or ax is None:\n",
    "        fig, ax = plt.subplots()\n",
    "    tsne = TSNE(n_components=2, random_state=0, perplexity=10, n_iter=1000)\n",
    "    X_2d = tsne.fit_transform(data)\n",
    "    for i in range(len(labels)):\n",
    "        plt.scatter(X_2d[i::len(labels), 0], X_2d[i::len(labels), 1], c=colors[i // len(markers)], marker=markers[i % len(markers)], label=labels[i])\n",
    "    plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    plt.title(title)\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    plt.savefig(os.path.join([output_dir, f'{title}.pdf']), bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# for timestep in timesteps:\n",
    "#     data_conditioned, data_unconditioned = load_data(timestep, repeitions)\n",
    "#     data_conditioned = preprocess_data(data_conditioned, repeitions, classes)    \n",
    "#     draw_tsne(data_conditioned, prompts, colors, markers, title=f'Conditioned at timestep {timestep}')\n",
    "#     data_unconditioned = preprocess_data(data_unconditioned, repeitions, classes)\n",
    "#     draw_tsne(data_unconditioned, prompts, colors, markers, title=f'Unconditioned at timestep {timestep}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = 64\n",
    "repeitions = 10\n",
    "\n",
    "with open('../assets/texts/direction_number_text_prompts_64.txt', 'r') as f:\n",
    "    prompts = f.readlines()\n",
    "    prompts = [p.strip() for p in prompts]\n",
    "\n",
    "timesteps = list(range(0, 999, 50))\n",
    "timesteps.append(999)\n",
    "\n",
    "# Draw 16 different colors and 4 different markers\n",
    "colors = ['#FFA07A', '#00CED1', '#BA55D3', '#FFD700',\n",
    "          '#008080', '#FF69B4', '#800000', '#8B4513',\n",
    "          '#2E8B57', '#FFFF00', '#00BFFF', '#FF00FF',\n",
    "          '#FF8C00', '#808000', '#FF6347', '#00FFFF']\n",
    "markers = ['o', 'v', 's', 'p']\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(17, 17))\n",
    "axs = axs.flatten()\n",
    "\n",
    "for idx, time_step in enumerate([999, 900, 750, 0]):\n",
    "    np.random.seed(42)\n",
    "    tsne = TSNE(n_components=2, random_state=0, perplexity=10, n_iter=1000)\n",
    "\n",
    "    data, _ = load_data(time_step, repeitions)\n",
    "    data = preprocess_data(data, repeitions, classes)\n",
    "    X_2d = tsne.fit_transform(data)\n",
    "    for i in range(len(prompts)):\n",
    "        axs[idx].scatter(X_2d[i::len(prompts), 0], X_2d[i::len(prompts), 1], c=colors[i // len(markers)], marker=markers[i % len(markers)], label=prompts[i])\n",
    "    axs[idx].set_title(f'timestep {time_step}')\n",
    "    axs[idx].set_xlabel('t-SNE dimension 1', fontsize=12)\n",
    "    axs[idx].set_ylabel('t-SNE dimension 2', fontsize=12)\n",
    "\n",
    "# Adjust the spacing between the subplots and the legend\n",
    "fig.subplots_adjust(bottom=0.27)\n",
    "# fig.text(0.1, 0.4, 't-SNE dimension 2', va='center', rotation='vertical', fontsize=12)\n",
    "# fig.text(0.1, 0.75, 't-SNE dimension 2', va='center', rotation='vertical', fontsize=12)\n",
    "\n",
    "# Place the legend below the subplots\n",
    "fig.legend(loc='lower center', ncol=4, labels=prompts, fontsize=12)\n",
    "\n",
    "output_dir='../assets/pdf/latent_vec_64'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "fig.savefig(os.path.join(output_dir, f'latent_vec_64.pdf'), bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mdm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cf8f9faf42866fdcd07a58468c0a330e2dab640d2d2c1294540c4a766bac15a7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
